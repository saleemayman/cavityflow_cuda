#!/bin/sh

# The Hydra cluster uses IBM's LoadLeveler as job scheduler: llsubmit. As
# parameter it only expects a job script (jobscript.sh) which contains all
# relevant information concerning the set up of the parallel environment and the
# execution of the parallel program.
# 
# It's not possible to pass any arguments to this job script so the job script
# sets up the ressource allocation according to to such parameters. That's the
# reason why the job scripts are first generated by python before they are passed
# to llsubmit.

let maxNumOfNodes=32
let numOfGPUsPerNode=2
let numOfRanksPerNode=${numOfGPUsPerNode}
let numOfThreadsPerProcess=1
let numOfThreadsPerNode=numOfThreadsPerProcess*numOfRanksPerNode
let amountOfMemPerProcess=4
let amountOfMemPerNode=${numOfGPUsPerNode}*${amountOfMemPerProcess}

# The place option forces distribution of chunks among nodes even insufficient
# data is offered 
# free:    As many chunks as possible are scheduled on one single node (depends
#          on job queue (e.g. 24 for S queue)) before a second node is used
# scatter: Scatters chunks (numer after = sign) among different nodes, so
#          different chunks would be scheduled on the same node
# pack:    At maximum, one node is allocated
place="scatter"

echo "maxNumOfNodes:          "${maxNumOfNodes}
echo "numOfGPUsPerNode:       "${numOfGPUsPerNode}
echo "numOfRanksPerNode:      "${numOfRanksPerNode}
echo "numOfThreadsPerProcess: "${numOfThreadsPerProcess}
echo "numOfThreadsPerNode:    "${numOfThreadsPerNode}
echo "amountOfMemPerProcess:  "${amountOfMemPerProcess}"GB"
echo "amountOfMemPerNode:     "${amountOfMemPerNode}"GB"

for((numOfNodes=32; numOfNodes<=maxNumOfNodes; numOfNodes++))
do
	let numOfGPUs=numOfGPUsPerNode*numOfNodes
	let numOfRanks=numOfRanksPerNode*numOfNodes
	
	echo "Scheduling job on "${numOfNodes}" nodes, spawning "${numOfRanks}" MPI ranks to utilize "${numOfGPUs}" GPUs"

	python generate_configuration.py ${numOfNodes} ${numOfRanksPerNode} ${numOfThreadsPerProcess} ${HOME} /ptmp/${USER}
	python generate_jobscript.py ${numOfNodes} ${numOfRanksPerNode} ${numOfThreadsPerProcess} ${amountOfMemPerProcess} ${HOME}
	
	llsubmit jobscript.sh
done

